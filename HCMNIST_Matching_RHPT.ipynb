{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EsymOuS7JvPq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "import random\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA  # to apply PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm.auto import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cd-0CfYfKYtP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This cell describes the dataset generation of HCMNIST data and this code is sourced from https://github.com/anndvision/quince.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import typing\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import datasets\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "def lambda_top_func(mu, k, y, alpha):\n",
        "    m = y.shape[0]\n",
        "    r = (y[k:] - mu).sum(dim=0)\n",
        "    return mu + r.div(m * (alpha + 1) - k)\n",
        "\n",
        "\n",
        "def lambda_bottom_func(mu, k, y, alpha):\n",
        "    m = y.shape[0]\n",
        "    r = (y[:k] - mu).sum(dim=0)\n",
        "    return mu + r.div(m * alpha + k)\n",
        "\n",
        "\n",
        "def alpha_fn(pi, lambda_):\n",
        "    return (pi * lambda_) ** -1 + 1.0 - lambda_ ** -1\n",
        "\n",
        "\n",
        "def beta_fn(pi, lambda_):\n",
        "    return lambda_ * (pi) ** -1 + 1.0 - lambda_\n",
        "\n",
        "\n",
        "def policy_risk(pi, y1, y0):\n",
        "    return (pi * y1 + (1 - pi) * y0).mean()\n",
        "\n",
        "def complete_propensity(x, u, gamma, beta=0.75):\n",
        "    logit = beta * x + 0.5\n",
        "    nominal = (1 + np.exp(-logit)) ** -1\n",
        "    alpha = alpha_fn(nominal, gamma)\n",
        "    beta = beta_fn(nominal, gamma)\n",
        "    return (u / alpha) + ((1 - u) / beta)\n",
        "\n",
        "\n",
        "def f_mu(x, t, u, theta=4.0):\n",
        "    mu = (\n",
        "        (2 * t - 1) * x\n",
        "        + (2.0 * t - 1)\n",
        "        - 2 * np.sin((4 * t - 2) * x)\n",
        "        - (theta * u - 2) * (1 + 0.5 * x)\n",
        "    )\n",
        "    return mu\n",
        "\n",
        "\n",
        "def linear_normalization(x, new_min, new_max):\n",
        "    return (x - x.min()) * (new_max - new_min) / (x.max() - x.min()) + new_min\n",
        "\n",
        "\n",
        "class HCMNIST(datasets.MNIST):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        gamma_star: float,\n",
        "        split: str = \"train\",\n",
        "        mode: str = \"mu\",\n",
        "        p_u: str = \"bernoulli\",\n",
        "        theta: float = 4.0,\n",
        "        beta: float = 0.75,\n",
        "        sigma_y: float = 1.0,\n",
        "        domain: float = 2.0,\n",
        "        seed: int = 1331,\n",
        "        transform: typing.Optional[typing.Callable] = None,\n",
        "        target_transform: typing.Optional[typing.Callable] = None,\n",
        "        download: bool = True,\n",
        "    ) -> None:\n",
        "        train = split == \"train\" or split == \"valid\"\n",
        "        root = Path.home() / \"quince_datasets\" if root is None else Path(root)\n",
        "        self.__class__.__name__ = \"MNIST\"\n",
        "        super(HCMNIST, self).__init__(\n",
        "            root,\n",
        "            train=train,\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            download=download,\n",
        "        )\n",
        "        self.data = self.data.view(len(self.targets), -1).numpy()\n",
        "        self.targets = self.targets.numpy()\n",
        "\n",
        "        if train:\n",
        "            (\n",
        "                data_train,\n",
        "                data_valid,\n",
        "                targets_train,\n",
        "                targets_valid,\n",
        "            ) = model_selection.train_test_split(\n",
        "                self.data, self.targets, test_size=0.3, random_state=seed\n",
        "            )\n",
        "            self.data = data_train if split == \"train\" else data_valid\n",
        "            self.targets = targets_train if split == \"train\" else targets_valid\n",
        "\n",
        "        self.mode = mode\n",
        "        self.dim_input = [1, 28, 28]\n",
        "        self.dim_treatment = 1\n",
        "        self.dim_output = 1\n",
        "\n",
        "        self.phi_model = fit_phi_model(\n",
        "            root=root, edges=torch.arange(-domain, domain + 0.1, (2 * domain) / 10),\n",
        "        )\n",
        "\n",
        "        size = (self.__len__(), 1)\n",
        "        rng = np.random.RandomState(seed=seed)\n",
        "        if p_u == \"bernoulli\":\n",
        "            self.u = rng.binomial(1, 0.5, size=size).astype(\"float32\")\n",
        "        elif p_u == \"uniform\":\n",
        "            self.u = rng.uniform(size=size).astype(\"float32\")\n",
        "        elif p_u == \"beta_bi\":\n",
        "            self.u = rng.beta(0.5, 0.5, size=size).astype(\"float32\")\n",
        "        elif p_u == \"beta_uni\":\n",
        "            self.u = rng.beta(2, 5, size=size).astype(\"float32\")\n",
        "        else:\n",
        "            raise NotImplementedError(f\"{p_u} is not a supported distribution\")\n",
        "\n",
        "        phi = self.phi\n",
        "        self.pi = (\n",
        "            complete_propensity(x=phi, u=self.u, gamma=gamma_star, beta=beta)\n",
        "            .astype(\"float32\")\n",
        "            .ravel()\n",
        "        )\n",
        "        self.t = rng.binomial(1, self.pi).astype(\"float32\")\n",
        "        eps = (sigma_y * rng.normal(size=self.t.shape)).astype(\"float32\")\n",
        "        self.mu0 = (\n",
        "            f_mu(x=phi, t=0.0, u=self.u, theta=theta).astype(\"float32\").ravel()\n",
        "        )\n",
        "        self.mu1 = (\n",
        "            f_mu(x=phi, t=1.0, u=self.u, theta=theta).astype(\"float32\").ravel()\n",
        "        )\n",
        "        self.y0 = self.mu0 + eps\n",
        "        self.y1 = self.mu1 + eps\n",
        "        self.y = self.t * self.y1 + (1 - self.t) * self.y0\n",
        "        self.tau = self.mu1 - self.mu0\n",
        "        self.y_mean = np.array([0.0], dtype=\"float32\")\n",
        "        self.y_std = np.array([1.0], dtype=\"float32\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = ((self.data[index].astype(\"float32\") / 255.0) - 0.1307) / 0.3081\n",
        "        t = self.t[index : index + 1]\n",
        "        if self.mode == \"pi\":\n",
        "            return x, t\n",
        "        elif self.mode == \"mu\":\n",
        "            return np.hstack([x, t]), self.y[index : index + 1]\n",
        "        else:\n",
        "            raise NotImplementedError(\n",
        "                f\"{self.mode} not supported. Choose from 'pi'  for propensity models or 'mu' for expected outcome models\"\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def phi(self):\n",
        "        x = ((self.data.astype(\"float32\") / 255.0) - 0.1307) / 0.3081\n",
        "        z = np.zeros_like(self.targets.astype(\"float32\"))\n",
        "        for k, v in self.phi_model.items():\n",
        "            ind = self.targets == k\n",
        "            x_ind = x[ind].reshape(ind.sum(), -1)\n",
        "            means = x_ind.mean(axis=-1)\n",
        "            z[ind] = linear_normalization(\n",
        "                np.clip((means - v[\"mu\"]) / v[\"sigma\"], -1.4, 1.4), v[\"lo\"], v[\"hi\"]\n",
        "            )\n",
        "        return np.expand_dims(z, -1)\n",
        "\n",
        "    @property\n",
        "    def x(self):\n",
        "        return ((self.data.astype(\"float32\") / 255.0) - 0.1307) / 0.3081\n",
        "\n",
        "\n",
        "def fit_phi_model(root, edges):\n",
        "    ds = datasets.MNIST(root=root)\n",
        "    data = (ds.data.float().div(255) - 0.1307).div(0.3081).view(len(ds), -1)\n",
        "    model = {}\n",
        "    digits = torch.unique(ds.targets)\n",
        "    for i, digit in enumerate(digits):\n",
        "        lo, hi = edges[i : i + 2]\n",
        "        ind = ds.targets == digit\n",
        "        data_ind = data[ind].view(ind.sum(), -1)\n",
        "        means = data_ind.mean(dim=-1)\n",
        "        mu = means.mean()\n",
        "        sigma = means.std()\n",
        "        model.update(\n",
        "            {\n",
        "                digit.item(): {\n",
        "                    \"mu\": mu.item(),\n",
        "                    \"sigma\": sigma.item(),\n",
        "                    \"lo\": lo.item(),\n",
        "                    \"hi\": hi.item(),\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y1gQV3pNJFwv"
      },
      "outputs": [],
      "source": [
        "def get_HMINIST_data(sim_num):\n",
        "  obj = HCMNIST(root = \"./\",gamma_star = 1.1, seed=sim_num)\n",
        "  # Assuming X is a matrix of size (42000, 784)\n",
        "  # Assuming indices is the array of generated indices\n",
        "  indices = np.random.choice(42000, size=3000, replace=False)\n",
        "  # Select subrows from X using the generated indices\n",
        "\n",
        "  X = obj.x[indices]\n",
        "  Y_factual = obj.y[indices]\n",
        "  T = obj.t[indices]\n",
        "  mu_0 = obj.mu0[indices]\n",
        "  mu_1 = obj.mu1[indices]\n",
        "\n",
        "  X_train, X_test, Y_factual_train, _, T_train, _, mu_0_train, mu_0_test, mu_1_train, mu_1_test = train_test_split(X, Y_factual, T, mu_0, mu_1, test_size=0.1, random_state=sim_num)\n",
        "  # X_train, X_test, Y_factual_train, _, T_train, _, mu_0_train, mu_0_test, mu_1_train, mu_1_test = train_test_split(X, Y_factual, T, mu_0, mu_1, test_size=0.0000001, random_state=sim_num)\n",
        "\n",
        "  X_train = X_train.astype('float32')\n",
        "  Y_factual_train = Y_factual_train.astype('float32')\n",
        "  T_train = T_train.astype('float32')\n",
        "  mu_0_train = mu_0_train.astype('float32')\n",
        "  mu_1_train = mu_1_train.astype('float32')\n",
        "\n",
        "  X_test = X_test.astype('float32')\n",
        "  mu_0_test = mu_0_test.astype('float32')\n",
        "  mu_1_test = mu_1_test.astype('float32')\n",
        "\n",
        "  return (X_train, Y_factual_train, T_train, mu_0_train, mu_1_train), (X_test, mu_0_test, mu_1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LPFkX_WDK-Rp"
      },
      "outputs": [],
      "source": [
        "def random_matching_IN(X, Y, T):\n",
        "  preds_IN_random = {}\n",
        "\n",
        "  X_treated, X_control = get_separate_treated_and_control(X,T)\n",
        "  Y_treated, Y_control = get_separate_treated_and_control(Y,T)\n",
        "\n",
        "\n",
        "  untreated_group_selected = random.choices(range(0, len(Y_control)), k=len(Y_treated))\n",
        "\n",
        "  treated_group_selected = random.choices(range(0, len(Y_treated)), k=len(Y_control))\n",
        "\n",
        "  preds_IN_random['trtd_grp_y0'] = Y_control[untreated_group_selected]\n",
        "\n",
        "  preds_IN_random['trtd_grp_y1'] = Y_treated\n",
        "\n",
        "  preds_IN_random['cntrl_grp_y0'] = Y_control\n",
        "\n",
        "  preds_IN_random['cntrl_grp_y1'] = Y_treated[treated_group_selected]\n",
        "\n",
        "  return preds_IN_random\n",
        "\n",
        "def random_matching_OUT(X_in, Y_in, T_in, X_out):\n",
        "  preds_OUT_random = {}\n",
        "\n",
        "  X_in_trtd, X_in_cntrl = get_separate_treated_and_control(X_in, T_in)\n",
        "  Y_in_trtd, Y_in_cntrl = get_separate_treated_and_control(Y_in, T_in)\n",
        "\n",
        "\n",
        "  untreated_group_selected = random.choices(range(0, len(Y_in_cntrl)), k=np.shape(X_out)[0] )\n",
        "\n",
        "  treated_group_selected = random.choices(range(0, len(Y_in_trtd)), k=np.shape(X_out)[0])\n",
        "\n",
        "  preds_OUT_random['y0'] = Y_in_cntrl[untreated_group_selected]\n",
        "\n",
        "  preds_OUT_random['y1'] = Y_in_trtd[treated_group_selected]\n",
        "\n",
        "  return preds_OUT_random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SAFb_HU5LAS4"
      },
      "outputs": [],
      "source": [
        "def matching_algo_with_out(distance_type, X_IN, Y_IN, T_IN, X_OUT):\n",
        "\n",
        "  global hash_length\n",
        "\n",
        "  preds_IN = {}\n",
        "  preds_OUT = {}\n",
        "\n",
        "  if distance_type == \"random\":\n",
        "    preds_IN = random_matching_IN(X_IN, Y_IN, T_IN)\n",
        "    preds_OUT = random_matching_OUT(X_IN, Y_IN, T_IN, X_OUT)\n",
        "\n",
        "  else:\n",
        "\n",
        "    X_IN_trtd, X_IN_cntrl = get_separate_treated_and_control(X_IN, T_IN)\n",
        "    Y_IN_trtd, Y_IN_cntrl = get_separate_treated_and_control(Y_IN, T_IN)\n",
        "\n",
        "    if distance_type == \"hamming\":\n",
        "      treat_untreated_dist_IN =  np.square(pairwise_distances(X_IN_trtd, X_IN_cntrl, metric='euclidean', n_jobs=-1))/hash_length\n",
        "\n",
        "    else:\n",
        "      treat_untreated_dist_IN = pairwise_distances(X_IN_trtd, X_IN_cntrl, metric=distance_type, n_jobs=-1)\n",
        "\n",
        "    cntrl_grp_selected_IN = np.argmin(treat_untreated_dist_IN, axis=1)\n",
        "    trtd_grp_selected_IN = np.argmin(treat_untreated_dist_IN, axis=0)\n",
        "\n",
        "    preds_IN['trtd_grp_y0'] = Y_IN_cntrl[cntrl_grp_selected_IN]\n",
        "\n",
        "    preds_IN['trtd_grp_y1'] = Y_IN_trtd\n",
        "\n",
        "    preds_IN['cntrl_grp_y0'] = Y_IN_cntrl\n",
        "\n",
        "    preds_IN['cntrl_grp_y1'] = Y_IN_trtd[trtd_grp_selected_IN]\n",
        "\n",
        "    # Doing prediction on outsample test\n",
        "\n",
        "    if distance_type == \"hamming\":\n",
        "      X_OUT_vs_X_IN_cntrl_dist = np.square(pairwise_distances(X_OUT, X_IN_cntrl, metric='euclidean', n_jobs=-1))/hash_length\n",
        "      X_OUT_vs_X_IN_trtd_dist = np.square(pairwise_distances(X_OUT, X_IN_trtd, metric='euclidean', n_jobs=-1))/hash_length\n",
        "\n",
        "    else:\n",
        "      X_OUT_vs_X_IN_cntrl_dist = pairwise_distances(X_OUT, X_IN_cntrl, metric=distance_type, n_jobs=-1)\n",
        "      X_OUT_vs_X_IN_trtd_dist = pairwise_distances(X_OUT, X_IN_trtd, metric=distance_type, n_jobs=-1)\n",
        "\n",
        "    cntrl_grp_selected_OUT = np.argmin(X_OUT_vs_X_IN_cntrl_dist, axis=1)\n",
        "    trtd_grp_selected_OUT = np.argmin(X_OUT_vs_X_IN_trtd_dist, axis=1)\n",
        "\n",
        "    preds_OUT['y0'] = Y_IN_cntrl[cntrl_grp_selected_OUT]\n",
        "\n",
        "    preds_OUT['y1'] = Y_IN_trtd[trtd_grp_selected_OUT]\n",
        "\n",
        "  return preds_IN, preds_OUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "deZpPzCZLB7v"
      },
      "outputs": [],
      "source": [
        "class Eval_metrics_In_sample():\n",
        "    #EVAL METRICS FOR INSMAPLES ----------------\n",
        "    def __init__(self,mu_0, mu_1, T):\n",
        "        self.data={}\n",
        "\n",
        "        mu_0_trted, mu_0_cntrl = get_separate_treated_and_control(mu_0, T)\n",
        "\n",
        "        mu_1_trted, mu_1_cntrl = get_separate_treated_and_control(mu_1, T)\n",
        "\n",
        "        self.data['trtd_grp_mu_0'] = mu_0_trted\n",
        "        self.data['cntrl_grp_mu_0'] = mu_0_cntrl\n",
        "\n",
        "        self.data['trtd_grp_mu_1'] = mu_1_trted\n",
        "        self.data['cntrl_grp_mu_1'] = mu_1_cntrl\n",
        "\n",
        "    def ATE_absolute_error(self,preds):\n",
        "\n",
        "        ITTs_pred =  preds['trtd_grp_y1'] - preds['trtd_grp_y0']\n",
        "        ITUs_pred =  preds['cntrl_grp_y1'] - preds['cntrl_grp_y0']\n",
        "        ATE_pred = np.mean(np.concatenate((ITTs_pred, ITUs_pred)))\n",
        "\n",
        "        ITTs_true =  self.data['trtd_grp_mu_1']  - self.data['trtd_grp_mu_0']\n",
        "        ITUs_true =  self.data['cntrl_grp_mu_1']  - self.data['cntrl_grp_mu_0']\n",
        "        ATE_true = np.mean(np.concatenate((ITTs_true, ITUs_true)))\n",
        "\n",
        "        # print(\"TrueATE:- \",ATE_true)\n",
        "        # print(\"PredATE:- \",ATE_pred)\n",
        "        # print(\"--------------------\")\n",
        "        return np.abs(ATE_true- ATE_pred)\n",
        "\n",
        "\n",
        "    def ITE_RMSE_func(self,preds):\n",
        "\n",
        "        ITTs_pred =  preds['trtd_grp_y1'] - preds['trtd_grp_y0']\n",
        "        ITUs_pred =  preds['cntrl_grp_y1'] - preds['cntrl_grp_y0']\n",
        "        ITE_pred = np.concatenate((ITTs_pred, ITUs_pred))\n",
        "\n",
        "        ITTs_true =  self.data['trtd_grp_mu_1']  - self.data['trtd_grp_mu_0']\n",
        "        ITUs_true =  self.data['cntrl_grp_mu_1']  - self.data['cntrl_grp_mu_0']\n",
        "        ITE_true = np.concatenate((ITTs_true, ITUs_true))\n",
        "\n",
        "        ITE_RMSE = np.sqrt(np.mean(np.square(ITE_true - ITE_pred)))\n",
        "\n",
        "        return ITE_RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DQDsYLEtLEsi"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Eval_metrics_Out_sample():\n",
        "    #EVAL METRICS FOR OUT SMAPLES -----------------\n",
        "    def __init__(self,mu_0, mu_1):\n",
        "        self.data={}\n",
        "\n",
        "        self.data['mu_0'] = mu_0\n",
        "        self.data['mu_1'] = mu_1\n",
        "\n",
        "    def ATE_absolute_error(self,preds):\n",
        "\n",
        "        ATE_pred = np.mean(preds['y1'] - preds['y0'])\n",
        "        ATE_true = np.mean(self.data['mu_1'] - self.data['mu_0'])\n",
        "\n",
        "\n",
        "\n",
        "        return np.abs(ATE_true- ATE_pred)\n",
        "\n",
        "    def PEHE_func(self,preds):\n",
        "\n",
        "        PEHE = np.sqrt(np.mean(( np.square( ( (self.data['mu_1']-self.data['mu_0']) - (preds['y1']-preds['y0']) ) ) )))\n",
        "\n",
        "        return PEHE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zvz4ZsTkkwkX"
      },
      "outputs": [],
      "source": [
        "def get_separate_treated_and_control(Q,T):\n",
        "  Q_treated = Q[T.astype(bool)]\n",
        "  Q_control = Q[np.logical_not(T.astype(bool))]\n",
        "  return Q_treated, Q_control\n",
        "\n",
        "def perform_PCA(IN_data_matrix, OUT_data_matrix):\n",
        "  pca = PCA(n_components=5)\n",
        "  pca.fit(IN_data_matrix)\n",
        "  Z_IN = pca.transform(IN_data_matrix)\n",
        "  Z_OUT = pca.transform(OUT_data_matrix)\n",
        "  return Z_IN, Z_OUT\n",
        "\n",
        "def create_hash(IN_data_matrix, OUT_data_matrix):\n",
        "  global hash_length\n",
        "  mid = (int) (hash_length/2)\n",
        "  random_matrix = np.random.randn(hash_length,np.shape(IN_data_matrix)[1]).T\n",
        "  lmbda = np.random.uniform(low=-5, high=5, size=(1,mid))\n",
        "\n",
        "  Z_IN = np.dot(IN_data_matrix, random_matrix)\n",
        "\n",
        "\n",
        "\n",
        "  Z_IN[:,mid:] = np.add(Z_IN[:,mid:], np.tile(lmbda, (np.shape(Z_IN)[0], 1)))\n",
        "  Z_IN = Z_IN > 0\n",
        "  Z_IN = Z_IN.astype(int)\n",
        "\n",
        "  Z_OUT = np.dot(OUT_data_matrix, random_matrix)\n",
        "  Z_OUT[:,mid:] = np.add(Z_OUT[:,mid:], np.tile(lmbda, (np.shape(Z_OUT)[0], 1)))\n",
        "  Z_OUT = Z_OUT > 0\n",
        "  Z_OUT = Z_OUT.astype(int)\n",
        "  return Z_IN, Z_OUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uoj3DkMiLGJN"
      },
      "outputs": [],
      "source": [
        "hash_length = 10000 # Hash vector length\n",
        "def select_baseline(choice, covs_in, treats_in, covs_out):\n",
        "  if choice == 1:\n",
        "    return  \"random\", covs_in, covs_out\n",
        "\n",
        "  elif choice == 2:\n",
        "    return \"l2\", covs_in, covs_out\n",
        "\n",
        "  elif choice == 3:\n",
        "    covs_in, covs_out = perform_PCA(covs_in, covs_out)\n",
        "    return \"l2\", covs_in, covs_out\n",
        "\n",
        "\n",
        "\n",
        "  elif choice == 4:\n",
        "    propensity_score_model_X = LogisticRegression(solver='liblinear', class_weight = \"balanced\").fit(covs_in, treats_in)\n",
        "    e_X_in = propensity_score_model_X.predict_proba(covs_in)[:,0]\n",
        "    e_X_out = propensity_score_model_X.predict_proba(covs_out)[:,0]\n",
        "\n",
        "    e_X_in = e_X_in.reshape(-1,1)\n",
        "    e_X_out = e_X_out.reshape(-1,1)\n",
        "    return \"l1\", e_X_in, e_X_out\n",
        "\n",
        "  elif choice == 5:\n",
        "    covs_in, covs_out = perform_PCA(covs_in, covs_out)\n",
        "    propensity_score_model_Z = LogisticRegression(solver='liblinear', class_weight = \"balanced\").fit(covs_in, treats_in)\n",
        "\n",
        "    e_Z_in = propensity_score_model_Z.predict_proba(covs_in)[:,0]\n",
        "    e_Z_out = propensity_score_model_Z.predict_proba(covs_out)[:,0]\n",
        "\n",
        "    e_Z_in = e_Z_in.reshape(-1,1)\n",
        "    e_Z_out = e_Z_out.reshape(-1,1)\n",
        "    return \"l1\", e_Z_in, e_Z_out\n",
        "\n",
        "  elif choice == 6:\n",
        "    covs_in, covs_out = create_hash(covs_in, covs_out)\n",
        "    return \"hamming\", covs_in, covs_out\n",
        "\n",
        "  else:\n",
        "    print(\"WRONG CHOICE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LuNuW58ULHuF"
      },
      "outputs": [],
      "source": [
        "def run_exp(choice):\n",
        "  error_ATE_in_sample =[]\n",
        "  RMSE_ITE_in_sample =[]\n",
        "\n",
        "  error_ATE_out_sample =[]\n",
        "  PEHE_out_sample =[]\n",
        "  dataset_sim_num = 100\n",
        "  choice_map = {1:\"Random\", 2:\"X\", 3:\"PCA(X)\", 4:\"e(X)\", 5:\"e(PCA(X))\", 6:\"RHPT\"} # e() is propensity score\n",
        "  for i in tqdm(range(1, dataset_sim_num+1), desc=\"HCMNIST Dataset Sim-Experiments Progress\"):\n",
        "\n",
        "    np.random.seed(i)\n",
        "    train_data, test_data = get_HMINIST_data(i)\n",
        "\n",
        "    X_in, Y_in, T_in, mu_0_in, mu_1_in = train_data\n",
        "\n",
        "    X_out, mu_0_out, mu_1_out = test_data\n",
        "\n",
        "    distance_type, X_in, X_out = select_baseline(choice, X_in, T_in, X_out)\n",
        "\n",
        "    preds_in, preds_out = matching_algo_with_out(distance_type, X_in, Y_in, T_in, X_out)\n",
        "\n",
        "    in_sample_evals = Eval_metrics_In_sample(mu_0 = mu_0_in, mu_1 = mu_1_in, T = T_in)\n",
        "    out_sample_evals = Eval_metrics_Out_sample(mu_0=mu_0_out, mu_1=mu_1_out)\n",
        "\n",
        "    error_ATE_in_sample.append(in_sample_evals.ATE_absolute_error(preds_in))\n",
        "    RMSE_ITE_in_sample.append(in_sample_evals.ITE_RMSE_func(preds_in))\n",
        "\n",
        "    error_ATE_out_sample.append(out_sample_evals.ATE_absolute_error(preds_out))\n",
        "    PEHE_out_sample.append(out_sample_evals.PEHE_func(preds_out))\n",
        "\n",
        "  print(\"In-sample ATE absolute error for \",choice_map[choice],\" matching =\", round(np.mean(error_ATE_in_sample),2),\"+-\", round((np.std(error_ATE_in_sample, ddof=1) / np.sqrt(np.size(error_ATE_in_sample))),2))\n",
        "  print(\"In-sample ITE RMSE for \",choice_map[choice],\" matching =\", round(np.mean(RMSE_ITE_in_sample),2),\"+-\", round((np.std(RMSE_ITE_in_sample, ddof=1) / np.sqrt(np.size(RMSE_ITE_in_sample))),2))\n",
        "  print(\"Out-sample ATE error for \",choice_map[choice],\" matching =\", round(np.mean(error_ATE_out_sample),2),\"+-\", round((np.std(error_ATE_out_sample, ddof=1) / np.sqrt(np.size(error_ATE_out_sample))),2))\n",
        "  print(\"Out-sample PEHE error for \",choice_map[choice],\" matching =\", round(np.mean(PEHE_out_sample),2),\"+-\", round((np.std(PEHE_out_sample, ddof=1) / np.sqrt(np.size(PEHE_out_sample))),2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "# choice_map = {1:\"Random\", 2:\"X\", 3:\"PCA(X)\", 4:\"e(X)\", 5:\"e(PCA(X))\", 6:\"RHPT\"} # e() is propensity score\n",
        "run_exp(choice=6) # Change choice for which baseline do you want\n",
        "end_time = time.time()\n",
        "elapsed_time_seconds = end_time - start_time\n",
        "# Convert elapsed time to minutes\n",
        "elapsed_time_minutes = elapsed_time_seconds / 60\n",
        "print(\"Time Taken in Minutes\", elapsed_time_minutes)"
      ],
      "metadata": {
        "id": "l1LwU3oR0Fbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "804abbb2a7fb49a0b13a7affdc2d69b2",
            "f3fc1a19f9094bf28ad4eefa0cf81e59",
            "9660f00aee214ec1bbdcfc81999d8d68",
            "81a731b0945144ca822e2dce9b0b4d6e",
            "a4bd7ca466204033a84e2cbb76d5d808",
            "4417e9551f304691a9c87a4be293d76c",
            "77a98109de9645be88fff12ea5090172",
            "69178fb816484f90ada4f8bc013bcd6b",
            "fb9f3f3b8dc9405199f4e442de818d0b",
            "28269a4ffbc24aef9dada97c342609bf",
            "01e468ce521743a59430597c01f5cd12"
          ]
        },
        "outputId": "2fe417c5-329a-40b8-d3a5-83150540750a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HCMNIST Dataset Sim-Experiments Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "804abbb2a7fb49a0b13a7affdc2d69b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-sample ATE absolute error for  RHPT  matching = 0.19 +- 0.01\n",
            "In-sample ITE RMSE for  RHPT  matching = 3.6 +- 0.01\n",
            "Out-sample ATE error for  RHPT  matching = 0.23 +- 0.02\n",
            "Out-sample PEHE error for  RHPT  matching = 3.75 +- 0.02\n",
            "Time Taken in Minutes 9.359491340319316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iikauqmZHZcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "804abbb2a7fb49a0b13a7affdc2d69b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3fc1a19f9094bf28ad4eefa0cf81e59",
              "IPY_MODEL_9660f00aee214ec1bbdcfc81999d8d68",
              "IPY_MODEL_81a731b0945144ca822e2dce9b0b4d6e"
            ],
            "layout": "IPY_MODEL_a4bd7ca466204033a84e2cbb76d5d808"
          }
        },
        "f3fc1a19f9094bf28ad4eefa0cf81e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4417e9551f304691a9c87a4be293d76c",
            "placeholder": "​",
            "style": "IPY_MODEL_77a98109de9645be88fff12ea5090172",
            "value": "HCMNIST Dataset Sim-Experiments Progress: 100%"
          }
        },
        "9660f00aee214ec1bbdcfc81999d8d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69178fb816484f90ada4f8bc013bcd6b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb9f3f3b8dc9405199f4e442de818d0b",
            "value": 100
          }
        },
        "81a731b0945144ca822e2dce9b0b4d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28269a4ffbc24aef9dada97c342609bf",
            "placeholder": "​",
            "style": "IPY_MODEL_01e468ce521743a59430597c01f5cd12",
            "value": " 100/100 [09:21&lt;00:00,  5.55s/it]"
          }
        },
        "a4bd7ca466204033a84e2cbb76d5d808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4417e9551f304691a9c87a4be293d76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a98109de9645be88fff12ea5090172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69178fb816484f90ada4f8bc013bcd6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9f3f3b8dc9405199f4e442de818d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28269a4ffbc24aef9dada97c342609bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e468ce521743a59430597c01f5cd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
